{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../emnist/emnist-letters-train.csv', header=None)\n",
    "test_df = pd.read_csv('../emnist/emnist-letters-test.csv', header=None)\n",
    "\n",
    "y_train = train_df.iloc[:, 0].values - 1\n",
    "x_train = train_df.iloc[:, 1:].values\n",
    "y_test = test_df.iloc[:, 0].values - 1\n",
    "x_test = test_df.iloc[:, 1:].values\n",
    "\n",
    "# Normalisation\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Standardisation\n",
    "X_mean = x_train.mean(axis=0)\n",
    "X_std = x_train.std(axis=0)\n",
    "X_std = np.where(X_std == 0, 1, X_std)\n",
    "X_train_standardized = (x_train - X_mean) / X_std\n",
    "\n",
    "# PCA\n",
    "n_components = 100\n",
    "pca = PCA(n_components=n_components)\n",
    "x_train_pca = pca.fit_transform(X_train_standardized)\n",
    "\n",
    "# Préparation pour CNN (reshape 100 -> 10x10)\n",
    "x_train_pca_reshaped = x_train_pca.reshape(-1, 10, 10, 1)\n",
    "\n",
    "# Création du modèle CNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(10, 10, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),  # Ajout d'un dropout pour éviter le surapprentissage\n",
    "    tf.keras.layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "# Entraînement\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Entraînement avec validation split\n",
    "history = model.fit(\n",
    "    x_train_pca_reshaped, \n",
    "    y_train, \n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Sauvegarde des composants nécessaires\n",
    "np.savez('arrays_emnist.npz',\n",
    "         principal_components=pca.components_.T,  # Transposée pour la multiplication matricielle\n",
    "         X_mean=X_mean,\n",
    "         X_std=X_std)\n",
    "\n",
    "# Sauvegarde du modèle CNN\n",
    "model.save('emnist_cnn_pca_model.keras')\n",
    "\n",
    "# Affichage des performances\n",
    "print(\"Performances finales:\")\n",
    "test_standardized = (x_test - X_mean) / X_std\n",
    "test_pca = np.dot(test_standardized, pca.components_.T)\n",
    "test_pca_reshaped = test_pca.reshape(-1, 10, 10, 1)\n",
    "test_loss, test_accuracy = model.evaluate(test_pca_reshaped, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
